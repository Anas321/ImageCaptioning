{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Image_captioning_InceptV3_Flickr_data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anas321/ImageCaptioning/blob/master/Image_captioning_InceptV3_Flickr_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4FZ7iOvpUPS",
        "outputId": "2698587a-e11c-4ef8-a14e-2cad64e4bd81"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhRtvCUavjKN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ac512dec-e97d-4fca-bb3e-f7262e98ca44"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9JPungsup7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8af5bd-3672-4de0-f56e-9270de28059f"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/ImageCaptioning/InceptV3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ImageCaptioning/InceptV3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfP2X7Ym8L3Q"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoNg2t3SIEGl"
      },
      "source": [
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2JR6VIBSmPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b7cff1-9c62-44e7-8f02-3d18ef99dc3c"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "cleaned_descriptions.json\n",
            "features_for_all_images_Flickr_backup.pkl\n",
            "features_for_all_images_Flickr_NEW.pkl\n",
            "features_for_all_images_Flickr.pkl\n",
            "features_for_all_images_Inception_MSCOCO.pkl\n",
            "\u001b[01;34mFlicker8k_Dataset\u001b[0m/\n",
            "\u001b[01;34mFlickr8k_text\u001b[0m/\n",
            "Image_captioning_inceptV3_Flickr_main.ipynb\n",
            "Image_captioning_inceptV3_MSCOCO.ipynb\n",
            "\u001b[01;34m__MACOSX\u001b[0m/\n",
            "model.png\n",
            "\u001b[01;34mMODELS\u001b[0m/\n",
            "tokenizer.pkl\n",
            "\u001b[01;34mtrain2014\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUYluZZwJaGc"
      },
      "source": [
        "EXTRACT_IMAGES_FEATURES = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43lfVoIaJaF_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "# import collections\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "from os import listdir\n",
        "from pickle import dump\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEv1oU20JaHe"
      },
      "source": [
        "**Extract Images Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFXct8ZaJaHi"
      },
      "source": [
        "# Extract images features\n",
        "images_folder_train = 'Flicker8k_Dataset'\n",
        "all_images_features_file_name = 'features_for_all_images_Flickr_NEW.pkl'\n",
        "\n",
        "# extract features from each image\n",
        "def extract_images_features(directory):\n",
        "    # load the VGG16 model\n",
        "    model = InceptionV3()\n",
        "    # re-structure the model\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    # print model summary\n",
        "    print(model.summary())\n",
        "    # define all_features dictionery to store \n",
        "    # features for all images\n",
        "    all_features = dict()\n",
        "    #counter = 1\n",
        "    for name in tqdm(listdir(directory)):\n",
        "        # get an image from a file\n",
        "        filename = directory + '/' + name\n",
        "        #print(filename)\n",
        "        image = load_img(filename, target_size=(299,299))\n",
        "        # convert the image pixles to a numpy array\n",
        "        image = img_to_array(image)\n",
        "        #print(image.shape)\n",
        "        # reshape the created numpy array for the model\n",
        "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "        #print(image.shape)\n",
        "        # prepare the image for the VGG16 model\n",
        "        image = preprocess_input(image)\n",
        "        # get features\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        # get image id\n",
        "        image_name = name.split('.')[0]\n",
        "        #print(image_name)\n",
        "        # store feature in the features dictionery\n",
        "        all_features[image_name] = feature\n",
        "        #print(counter,'>', name)\n",
        "        #counter += 1\n",
        "    return all_features\n",
        "\n",
        "if EXTRACT_IMAGES_FEATURES == 1:\n",
        "    # extract features from all images\n",
        "    directory = images_folder_train\n",
        "    features = extract_images_features(directory)\n",
        "    print('Size of extracted features:', len(features))\n",
        "    # save to file\n",
        "    with open(all_images_features_file_name, 'wb') as f:\n",
        "        pickle.dump(features, f)\n",
        "#     dump(features, open('features_for_all_images_Inception_MSCOCO.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfuKolBt3NCe"
      },
      "source": [
        "**Parse Text Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7hwvEr13hMA",
        "outputId": "61f332a7-9b7d-48f6-af14-58cca97dd958"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "cleaned_descriptions.json\n",
            "features_for_all_images_Flickr_backup.pkl\n",
            "features_for_all_images_Flickr_NEW.pkl\n",
            "features_for_all_images_Flickr.pkl\n",
            "features_for_all_images_Inception_MSCOCO.pkl\n",
            "\u001b[01;34mFlicker8k_Dataset\u001b[0m/\n",
            "\u001b[01;34mFlickr8k_text\u001b[0m/\n",
            "Image_captioning_inceptV3_Flickr_main.ipynb\n",
            "Image_captioning_inceptV3_MSCOCO.ipynb\n",
            "\u001b[01;34m__MACOSX\u001b[0m/\n",
            "model.png\n",
            "\u001b[01;34mMODELS\u001b[0m/\n",
            "tokenizer.pkl\n",
            "\u001b[01;34mtrain2014\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSSz-wLY3jSd",
        "outputId": "cee7fa5c-c6df-469f-e81d-852e1efb95f4"
      },
      "source": [
        "# def parse_text_file(filename):\n",
        "\n",
        "percentage_of_selected_images = 1.0\n",
        "filename = 'Flickr8k_text/Flickr8k.token.txt'\n",
        "with open(filename, 'r') as f:\n",
        "  file_content = f.read()\n",
        "# Create a dictionary where keys are the images ids and values are the captions\n",
        "desc_dict = dict()\n",
        "for line in file_content.split('\\n'):\n",
        "  segments = line.split()\n",
        "  if len(segments) < 2:\n",
        "    continue\n",
        "  image_id = segments[0]\n",
        "  image_desc = segments[1:]\n",
        "  image_desc = ' '.join(image_desc)\n",
        "  if image_id not in desc_dict.keys():\n",
        "    desc_dict[image_id] = list()\n",
        "  desc_dict[image_id].append(image_desc)\n",
        "# select only percentage of the available images (for memory restrictions)\n",
        "if percentage_of_selected_images < 1.0:\n",
        "  num_of_selected_images = round(len(desc_dict.keys())*percentage_of_selected_images)\n",
        "  desc_dict = list(desc_dict.items())[0:num_of_selected_images]\n",
        "  desc_dict = dict(desc_dict)\n",
        "# Clean desc_dict\n",
        "for key, desc_list in desc_dict.items():\n",
        "  # Loop through the list for each key\n",
        "  for i in range(len(desc_list)):\n",
        "    current_desc = desc_list[i]\n",
        "    # Tokenize; i.e., split\n",
        "    current_desc = current_desc.split()\n",
        "    # Lower case all words\n",
        "    current_desc = [word.lower() for word in current_desc]\n",
        "    # Remove any words with length <= 1\n",
        "    current_desc = [word for word in current_desc if len(word)>1]\n",
        "    # Remove any puctuations\n",
        "    for j in range(len(current_desc)):\n",
        "      current_word = current_desc[j]\n",
        "      if not current_word.isalnum():\n",
        "        letters = list(current_word)\n",
        "        letters = [letter for letter in letters if letter not in string.punctuation]\n",
        "        current_desc[j] = ''.join(letters)\n",
        "    # Remove any words happen to contain numbers in them\n",
        "    current_desc = [word for word in current_desc if word.isalpha()]\n",
        "    # Join the splitted words together again\n",
        "    current_desc = ' '.join(current_desc)\n",
        "    # Add startseq and endseq\n",
        "    current_desc = 'startseq ' + current_desc + ' endseq'\n",
        "    # Assain it back to the dictionery for its corresponding key\n",
        "    desc_list[i] = current_desc\n",
        "    # Print length of desc_dict\n",
        "desc_dict.pop('2258277193_586949ec62')\n",
        "print('There are {:d} images.'.format(len(desc_dict)))\n",
        "# Save the cleaned descriptions as a json file\n",
        "with open('cleaned_descriptions.json', 'w') as f:\n",
        "  json.dump(desc_dict, f)\n",
        "print('\\nCleaned descriptions are saved in \\'cleaned_descriptions.json\\' file.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 8091 images.\n",
            "\n",
            "Cleaned descriptions are saved in 'cleaned_descriptions.json' file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDMPmzdD0oNH",
        "outputId": "20236d82-2527-4b83-cab2-4c48d233ff44"
      },
      "source": [
        "# desc_dict.pop('2258277193_586949ec62')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['startseq people waiting for the subway endseq',\n",
              " 'startseq some people looking out windows in large building endseq',\n",
              " 'startseq three people are waiting on train platform endseq',\n",
              " 'startseq three people standing at station endseq',\n",
              " 'startseq two woman and one man standing near train tracks endseq']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "_rbMks1m1C4T",
        "outputId": "f7ff0c0d-a34a-40e8-c517-e55df7140523"
      },
      "source": [
        "desc_dict['2258277193_586949ec62']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4a93dcbbd70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdesc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2258277193_586949ec62'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '2258277193_586949ec62'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDIKFZhFy4LK",
        "outputId": "1cadd586-c940-4b9d-ad4d-6cde5f384fcd"
      },
      "source": [
        "ll"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 999106\n",
            "drwx------ 2 root      4096 Nov  4 22:05 \u001b[0m\u001b[01;34mannotations\u001b[0m/\n",
            "-rw------- 1 root   3047050 Nov 23 02:00 cleaned_descriptions.json\n",
            "-rw------- 1 root 133296868 Nov 18 18:35 features_for_all_images_Flickr_backup.pkl\n",
            "-rw------- 1 root  67015398 Nov 18 20:02 features_for_all_images_Flickr_NEW.pkl\n",
            "-rw------- 1 root 133296868 Nov 16 17:57 features_for_all_images_Flickr.pkl\n",
            "-rw------- 1 root 686187837 Nov  3 17:40 features_for_all_images_Inception_MSCOCO.pkl\n",
            "drwx------ 2 root      4096 Nov 17 01:49 \u001b[01;34mFlicker8k_Dataset\u001b[0m/\n",
            "drwx------ 2 root      4096 Nov 17 01:51 \u001b[01;34mFlickr8k_text\u001b[0m/\n",
            "-rw------- 1 root     54178 Nov 23 01:55 Image_captioning_inceptV3_Flickr_main.ipynb\n",
            "-rw------- 1 root     67040 Nov 15 19:57 Image_captioning_inceptV3_MSCOCO.ipynb\n",
            "drwx------ 2 root      4096 Nov 17 01:49 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "-rw------- 1 root     66172 Nov 23 01:10 model.png\n",
            "drwx------ 2 root      4096 Nov  5 20:22 \u001b[01;34mMODELS\u001b[0m/\n",
            "-rw------- 1 root     25893 Nov 23 01:06 tokenizer.pkl\n",
            "drwx------ 2 root      4096 Nov  5 17:40 \u001b[01;34mtrain2014\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}